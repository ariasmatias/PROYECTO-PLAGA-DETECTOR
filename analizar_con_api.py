import cv2
import requests
from ultralytics import YOLO
from PIL import Image
import io

# ========================
# CONFIGURACI√ìN
# ========================
MODEL_PATH = "C:/Users/matia/OneDrive/IFTS/Procesamiendo de imagenes v2/yolov8n.pt"

# Modelo funcionando 100% con API HF
API_URL = "https://api-inference.huggingface.co/models/microsoft/resnet-50"

# Token (opcional para este modelo, pero lo dejamos)
TOKEN = "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"
HEADERS = {"Authorization": f"Bearer {TOKEN}"}

# ========================
# Cargar modelo YOLO
# ========================
model = YOLO(MODEL_PATH)
print("Modelo YOLO cargado correctamente.")

# ========================
# Funci√≥n: enviar recorte a HuggingFace
# ========================
def classify_crop(image_np):

    # Convertir recorte a PNG bytes
    _, buffer = cv2.imencode(".png", image_np)
    image_bytes = buffer.tobytes()

    headers = {
        "Content-Type": "image/png",
        "Authorization": f"Bearer {TOKEN}"
    }

    try:
        response = requests.post(API_URL, headers=headers, data=image_bytes, timeout=20)

        if response.status_code != 200:
            print("‚ùå Error HuggingFace:", response.status_code, response.text[:200])
            return None

        return response.json()

    except Exception as e:
        print("‚ùå Error enviando a HuggingFace:", str(e))
        return None


# ========================
# Funci√≥n principal
# ========================
def procesar_imagen(image_path):

    print("\nüì∏ Procesando imagen:", image_path)

    # Cargar imagen
    img = cv2.imread(image_path)
    if img is None:
        print("No se pudo leer la imagen.")
        return

    # Ejecutar YOLO
    print("üîç Detectando objetos...")
    results = model(img)

    # Procesar detecciones
    for i, box in enumerate(results[0].boxes):
        x1, y1, x2, y2 = map(int, box.xyxy[0])

        # Recortar regi√≥n detectada
        crop = img[y1:y2, x1:x2]

        # Guardar recorte localmente
        crop_filename = f"crop_{i+1}.jpg"
        cv2.imwrite(crop_filename, crop)
        print(f"üñº Recorte guardado: {crop_filename}")

        # Enviar recorte a HuggingFace
        print(f"\nüîé Enviando recorte {i+1} a HuggingFace...")
        response = classify_crop(crop)

        print("üìå Resultado HuggingFace:")
        print(response)

    print("\nüéâ Proceso completado.")


# ========================
# EJEMPLO DE USO
# ========================
procesar_imagen("foto_prueba.jpg")
